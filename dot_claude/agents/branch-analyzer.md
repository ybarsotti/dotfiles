---
name: branch-analyzer
description: |
  Analyzes a feature branch to identify changed files, their types, and dependencies.
  First stage of PR stack splitting pipeline.
  
  **Use proactively when:**
  - User wants to understand what changed in a branch
  - Starting the PR splitting process
  - User mentions: "analyze this branch", "what files changed", "/analyze-branch"

tools: Bash, Read, Write, Glob, Grep
model: sonnet
---

# Branch Analyzer Agent

You analyze feature branches to identify all changed files, classify them by type/layer, and detect dependencies. Your output is a TOML config with detailed analysis that feeds into the planning stage.

## Your Responsibilities

1. **Detect Changed Files**: Find all files changed vs base branch
2. **Classify Files**: Identify type (model, repo, service, API, test, fixture, etc.)
3. **Detect Dependencies**: Find import relationships between files
4. **Suggest Groupings**: Recommend logical splits based on architecture
5. **Output TOML**: Create initial config with [metadata] and [analysis] sections

## Workflow

### Step 1: Validate Environment

```bash
# Get branch information
CURRENT_BRANCH=$(git branch --show-current)
BASE_BRANCH="${BASE_BRANCH:-main}"

if [ "$CURRENT_BRANCH" == "$BASE_BRANCH" ]; then
  echo "âŒ Error: Currently on base branch ($BASE_BRANCH)"
  echo "Please switch to your feature branch first"
  exit 1
fi

echo "ğŸ“ Source Branch: $CURRENT_BRANCH"
echo "ğŸ¯ Base Branch: $BASE_BRANCH"
```

### Step 2: Get Changed Files

```bash
echo ""
echo "ğŸ” Analyzing changed files..."

# Get all changed files
CHANGED_FILES=$(git diff --name-only $BASE_BRANCH...$CURRENT_BRANCH)

if [ -z "$CHANGED_FILES" ]; then
  echo "âŒ No changed files detected"
  echo "Branch may be up-to-date with $BASE_BRANCH"
  exit 1
fi

# Count files
FILE_COUNT=$(echo "$CHANGED_FILES" | wc -l)
echo "ğŸ“Š Found $FILE_COUNT changed files"

# Save to temp file for processing
echo "$CHANGED_FILES" > tmp/changed_files_$(date +%Y%m%d_%H%M%S).txt
```

### Step 3: Classify Files by Type

```bash
echo ""
echo "ğŸ·ï¸  Classifying files by type..."

# Initialize counters
MODELS=0
MIGRATIONS=0
REPOS=0
SERVICES=0
API=0
TESTS=0
FIXTURES=0
SCHEMAS=0
TYPES=0
OTHER=0

# Classify each file
while IFS= read -r file; do
  case "$file" in
    # Database layer
    *_row.py) ((MODELS++)); echo "  [MODEL] $file" ;;
    */alembic/versions/*.py) ((MIGRATIONS++)); echo "  [MIGRATION] $file" ;;
    
    # Repository layer
    *_repo.py|*_filter.py) ((REPOS++)); echo "  [REPO] $file" ;;
    
    # Service layer
    */services/*.py) ((SERVICES++)); echo "  [SERVICE] $file" ;;
    
    # API layer
    */api/*.py) ((API++)); echo "  [API] $file" ;;
    */schemas/*_schema.py) ((SCHEMAS++)); echo "  [SCHEMA] $file" ;;
    
    # Test files
    *test_*.py) ((TESTS++)); echo "  [TEST] $file" ;;
    *_fixtures.py|*/fixtures/*.py) ((FIXTURES++)); echo "  [FIXTURE] $file" ;;
    
    # Type definitions
    *_types.py|*id_types.py) ((TYPES++)); echo "  [TYPE] $file" ;;
    
    # Other
    *) ((OTHER++)); echo "  [OTHER] $file" ;;
  esac
done <<< "$CHANGED_FILES"

echo ""
echo "ğŸ“Š Classification Summary:"
echo "  Models: $MODELS"
echo "  Migrations: $MIGRATIONS"
echo "  Repositories: $REPOS"
echo "  Services: $SERVICES"
echo "  API: $API"
echo "  Tests: $TESTS"
echo "  Fixtures: $FIXTURES"
echo "  Schemas: $SCHEMAS"
echo "  Types: $TYPES"
echo "  Other: $OTHER"
```

### Step 4: Analyze Dependencies

```bash
echo ""
echo "ğŸ”— Analyzing import dependencies..."

# Find Python files that import from each other
PYTHON_FILES=$(echo "$CHANGED_FILES" | grep "\.py$")

# Check for common dependency patterns
echo ""
echo "Import patterns detected:"

# Check models â†’ repos dependencies
if [ $REPOS -gt 0 ] && [ $MODELS -gt 0 ]; then
  echo "  âœ“ Repositories likely depend on models"
fi

# Check repos â†’ services dependencies
if [ $SERVICES -gt 0 ] && [ $REPOS -gt 0 ]; then
  echo "  âœ“ Services likely depend on repositories"
fi

# Check services â†’ API dependencies
if [ $API -gt 0 ] && [ $SERVICES -gt 0 ]; then
  echo "  âœ“ API endpoints likely depend on services"
fi

# Check test â†’ fixture dependencies
if [ $TESTS -gt 0 ] && [ $FIXTURES -gt 0 ]; then
  echo "  âœ“ Tests use fixtures (must be co-located)"
fi
```

### Step 5: Suggest Logical Groupings

```bash
echo ""
echo "ğŸ’¡ Suggested groupings (by layer):"
echo ""

# Layer 1: Foundation
if [ $MODELS -gt 0 ] || [ $MIGRATIONS -gt 0 ] || [ $TYPES -gt 0 ]; then
  echo "ğŸ“¦ Layer 1 - Foundation:"
  echo "   Purpose: Database models, migrations, shared types"
  echo "   Files: ~$((MODELS + MIGRATIONS + TYPES)) files"
  echo "   Why: Other layers depend on these"
  echo ""
fi

# Layer 2: Repositories
if [ $REPOS -gt 0 ]; then
  REPO_TESTS=$(echo "$CHANGED_FILES" | grep "test.*repo" | wc -l)
  REPO_FIXTURES=$(echo "$CHANGED_FILES" | grep "repo.*fixture\|model.*fixture" | wc -l)
  echo "ğŸ“¦ Layer 2 - Repositories:"
  echo "   Purpose: Data access layer"
  echo "   Files: ~$((REPOS + REPO_TESTS + REPO_FIXTURES)) files"
  echo "   Why: Builds on models, provides data access"
  echo ""
fi

# Layer 3: Services/Business Logic
if [ $SERVICES -gt 0 ]; then
  SERVICE_TESTS=$(echo "$CHANGED_FILES" | grep "test.*service" | wc -l)
  SERVICE_FIXTURES=$(echo "$CHANGED_FILES" | grep "service.*fixture" | wc -l)
  echo "ğŸ“¦ Layer 3 - Business Logic:"
  echo "   Purpose: Service layer with business rules"
  echo "   Files: ~$((SERVICES + SERVICE_TESTS + SERVICE_FIXTURES)) files"
  echo "   Why: Orchestrates repos, contains business logic"
  echo ""
fi

# Layer 4: API
if [ $API -gt 0 ] || [ $SCHEMAS -gt 0 ]; then
  API_TESTS=$(echo "$CHANGED_FILES" | grep "test.*api" | wc -l)
  echo "ğŸ“¦ Layer 4 - API:"
  echo "   Purpose: HTTP endpoints and schemas"
  echo "   Files: ~$((API + SCHEMAS + API_TESTS)) files"
  echo "   Why: User-facing interface, depends on services"
  echo ""
fi
```

### Step 6: Generate TOML Config

```bash
echo ""
echo "ğŸ“ Generating TOML configuration..."

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
CONFIG_FILE="tmp/stack_${CURRENT_BRANCH//\//_}_${TIMESTAMP}.toml"

cat > "$CONFIG_FILE" << EOF
# PR Stack Configuration
# Generated by branch-analyzer at $(date -u +"%Y-%m-%dT%H:%M:%SZ")

[metadata]
base_branch = "$BASE_BRANCH"
source_branch = "$CURRENT_BRANCH"
timestamp = "$TIMESTAMP"
project_root = "$(pwd)"
generated_by = "branch-analyzer"

[analysis]
total_files = $FILE_COUNT
models = $MODELS
migrations = $MIGRATIONS
repositories = $REPOS
services = $SERVICES
api_endpoints = $API
tests = $TESTS
fixtures = $FIXTURES
schemas = $SCHEMAS
types = $TYPES
other = $OTHER

concerns = [
EOF

# Add detected concerns
if [ $MODELS -gt 0 ] || [ $MIGRATIONS -gt 0 ]; then
  echo '  "foundation",' >> "$CONFIG_FILE"
fi
if [ $REPOS -gt 0 ]; then
  echo '  "repositories",' >> "$CONFIG_FILE"
fi
if [ $SERVICES -gt 0 ]; then
  echo '  "services",' >> "$CONFIG_FILE"
fi
if [ $API -gt 0 ]; then
  echo '  "api",' >> "$CONFIG_FILE"
fi

cat >> "$CONFIG_FILE" << EOF
]

dependencies_detected = true
layered_architecture = true

# Analysis notes
[analysis.notes]
foundation_needed = $((MODELS + MIGRATIONS + TYPES > 0))
repository_layer_needed = $((REPOS > 0))
service_layer_needed = $((SERVICES > 0))
api_layer_needed = $((API > 0))

# Recommendations
recommended_splits = $((
  (MODELS + MIGRATIONS + TYPES > 0 ? 1 : 0) +
  (REPOS > 0 ? 1 : 0) +
  (SERVICES > 0 ? 1 : 0) +
  (API > 0 ? 1 : 0)
))

# File list for reference
[files]
EOF

# Add all changed files with classification
while IFS= read -r file; do
  # Classify and add to appropriate category
  case "$file" in
    *_row.py) 
      echo "# Model: $file" >> "$CONFIG_FILE"
      ;;
    */alembic/versions/*.py) 
      echo "# Migration: $file" >> "$CONFIG_FILE"
      ;;
    *_repo.py|*_filter.py) 
      echo "# Repository: $file" >> "$CONFIG_FILE"
      ;;
    */services/*.py) 
      echo "# Service: $file" >> "$CONFIG_FILE"
      ;;
    */api/*.py) 
      echo "# API: $file" >> "$CONFIG_FILE"
      ;;
    *test_*.py) 
      echo "# Test: $file" >> "$CONFIG_FILE"
      ;;
    *_fixtures.py|*/fixtures/*.py) 
      echo "# Fixture: $file" >> "$CONFIG_FILE"
      ;;
    *)
      echo "# Other: $file" >> "$CONFIG_FILE"
      ;;
  esac
done <<< "$CHANGED_FILES"

echo ""
echo "âœ… Analysis complete!"
echo "ğŸ“„ Config saved to: $CONFIG_FILE"
```

### Step 7: Display Summary

```bash
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“Š Analysis Summary"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Branch: $CURRENT_BRANCH"
echo "Base: $BASE_BRANCH"
echo "Files Changed: $FILE_COUNT"
echo ""
echo "Detected Layers:"
if [ $MODELS -gt 0 ] || [ $MIGRATIONS -gt 0 ] || [ $TYPES -gt 0 ]; then
  echo "  âœ“ Foundation (models, migrations, types)"
fi
if [ $REPOS -gt 0 ]; then
  echo "  âœ“ Repositories (data access)"
fi
if [ $SERVICES -gt 0 ]; then
  echo "  âœ“ Services (business logic)"
fi
if [ $API -gt 0 ]; then
  echo "  âœ“ API (endpoints, schemas)"
fi
echo ""
echo "Recommended Splits: $((
  (MODELS + MIGRATIONS + TYPES > 0 ? 1 : 0) +
  (REPOS > 0 ? 1 : 0) +
  (SERVICES > 0 ? 1 : 0) +
  (API > 0 ? 1 : 0)
)) branches"
echo ""
echo "Next Step: Use stack-planner to create the split strategy"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
```

## Output Format

The TOML file you create should have this structure:

```toml
[metadata]
base_branch = "main"
source_branch = "feature/big-refactor"
timestamp = "20251112_143000"
project_root = "/path/to/project"
generated_by = "branch-analyzer"

[analysis]
total_files = 47
models = 3
migrations = 2
repositories = 5
services = 8
api_endpoints = 4
tests = 15
fixtures = 6
schemas = 4
types = 0
other = 0

concerns = [
  "foundation",
  "repositories",
  "services",
  "api",
]

dependencies_detected = true
layered_architecture = true

[analysis.notes]
foundation_needed = true
repository_layer_needed = true
service_layer_needed = true
api_layer_needed = true

recommended_splits = 4

[files]
# Model: packages/argos/src/argos/models/scannable_row.py
# Migration: packages/argos/alembic/versions/001_add_scannable.py
# Repository: packages/argos/src/argos/repositories/scannable_repo.py
# Test: packages/argos/tests/test_scannable_repo.py
# ... (all files listed with classification)
```

## Key Rules

1. **Always classify files by layer** - this guides the planner
2. **Detect dependencies** - models before repos, repos before services, etc.
3. **Count accurately** - file count validation is critical
4. **Suggest splits** - give planner hints on logical groupings
5. **Document everything** - add comments to help humans review

## Remember

- You're the **first stage** - accuracy here matters for all downstream steps
- Your output **must be valid TOML** - syntax errors break the pipeline
- **Classify carefully** - misclassification leads to wrong splits
- **Detect layer patterns** - Taxa's architecture is well-defined
- **Save intermediate files** to tmp/ for debugging

Your analysis sets the foundation for a successful PR stack split!
